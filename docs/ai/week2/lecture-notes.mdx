---
id: lecture-notes
title: Lecture Notes
hide_title: true
sidebar_position: 1
sidebar_label: Machine Learning
sidebar_class_name: icon-lecture
---

import ModuleBanner from '@site/src/components/ai/ai-banner';
import DefinitionBox from '@site/src/components/custom-admonitions/DefinitionBox';
import CenteredImage from '@site/src/components/image-changer/CenteredImage';
import {
  KeyPoints,
  KP,
} from '@site/src/components/custom-admonitions/KeyPoints';

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<ModuleBanner />

# Week 2: Machine Learning

#### Date:\*\* Saturday, 13 September 2025

---

## Definition of Machine Learning

---

<DefinitionBox term="Machine Learning Defined!">
  Machine Learning (ML) is a branch of Artificial Intelligence (AI) that focuses
  on developing algorithms and models that enable computer systems to
  automatically learn patterns and relationships from data, and improve their
  performance on a specific task over time, without being explicitly programmed
  with step-by-step instructions.
</DefinitionBox>

---


## Traditional Programming and Machine Learning

<div className="concept-card">
  <h3>Traditional Programming</h3>
  <p>
    In Traditional programming, a human developer analyzes a problem and writes
    explicit, hard-coded rules for the computer to follow. Think of it like a
    very detailed recipe.
  </p>
  <div className="example-box">
    <strong>Example:</strong> Spam Filter
    <ul>
      <li>
        A programmer might write a long list of rules like: IF the email
        contains the word "sale" AND "free", THEN mark as spam.
      </li>
      <li>The program's logic is entirely handcrafted by the developer.</li>
    </ul>
  </div>
</div>

<div className="concept-card">
  <h3>Machine Learning</h3>
  <p>
    In machine learning, the developer doesn't write the rules. Instead, they
    write a program that can learn the rules from data. The machine creates its
    own logic.
  </p>
  <div className="example-box">
    <strong>Example:</strong> Spam Filter
    <ul>
      <li>
        We give the model thousands of emails already labeled 'spam' or 'not
        spam'.
      </li>
      <li>
        The algorithm learns the patterns on its own—perhaps it discovers that
        certain phrases, sender domains, or even the time of day are highly
        predictive of spam.
      </li>
    </ul>
  </div>
</div>
<KeyPoints variant="primary" icon="❖">
  <KP term="Advantage of ML over Traditional Programming">
    <p>
      The biggest advantage of the machine learning approach is its scalability
      and adaptability.
    </p>
    <div className="cap-grid-2x1">
      <article className="cap-card">
        <h4>Traditional Programming</h4>
        <p>
          <ul>
            <li>
              A human programmer would have to constantly update the rules in a
              traditional spam filter.
            </li>
            <li>
              Spammers change their tactics, use new keywords, and find new ways
              to trick the system.
            </li>
            <li>
              A programmer would have to manually write a new rule for every new
              trick. This is a maintenance nightmare.
            </li>
          </ul>
        </p>
      </article>
      <br />
      <article className="cap-card">
        <h4>Machine Learning</h4>
        <p>
          <ul>
            <li>
              A machine learning model, on the other hand, can be retrained on
              new data.
            </li>
            <li>
              When it sees new examples of spam, it automatically learns the new
              patterns without a human having to explicitly program them.{' '}
            </li>
            <li>It adapts to the changing environment on its own.</li>
          </ul>
        </p>
      </article>
    </div>
  </KP>
</KeyPoints>
<figure className="image-card">
  <picture>
    {/* Optional WebP for smaller size; remove if you do not have it */}
    <source
      srcSet="/img/ai/week2/traditional-vs-machine-learning.png"
      type="image/png"
    />
    <img
      src="/img/ai/week2/traditional-vs-machine-learning.png"
      alt="Traditional Programming vs Machine Learning"
      loading="lazy"
      decoding="async"
      className="image-card__img"
    />
  </picture>
  <figcaption className="image-card__caption">
    Traditional Programming vs Machine Learning
  </figcaption>
</figure>
<figure className="image-card">
  <picture>
    {/* Optional WebP for smaller size; remove if you do not have it */}
    <source
      srcSet="/img/ai/week2/traditional-vs-machine-learning2.png"
      type="image/png"
    />
    <img
      src="/img/ai/week2/traditional-vs-machine-learning2.png"
      alt="Traditional Programming vs Machine Learning"
      loading="lazy"
      decoding="async"
      className="image-card__img"
    />
  </picture>
</figure>

<KeyPoints variant="primary" icon="❖">
  <KP term="Traditional Programming">
    In traditional programming, a function can be written that takes input in
    celsius and returns the output in fahrenheit using the formula

    $$
    F = {^{\circ}\mathrm{C}} \times 1.8 + 32
    $$
    <ul>
      <li> Note that the program was explicitly told the instructions to execute.</li>
    </ul>

  </KP>
  <KP term="Machine Learning">
    With Machine learning approach, the input and the output are known and the
    model learns the relationship between the input and the output.
  </KP>
</KeyPoints>

## Machine Learning Paradigms

#### The Spectrum of Learning: From Full Supervision to Trial and Error

<DefinitionBox term="Machine Learning Paradigms">
  <p>
    The paradigms of machine learning describe the different ways an algorithm
    can learn from data. Each paradigm is suited for different types of problems
    and data availability.
  </p>
</DefinitionBox>

{/* ===== Advanced MDX/CSS component: Learning Paradigms Deck ===== */}

<section class="ai-modes" aria-label="Machine Learning Paradigms">
  {/* --- Accessible tab controls (no JS) --- */}

{/* --- Panels (one code path, four states) --- */}

  <div class="ai-panels">
    <article id="panel-supervised" role="tabpanel" aria-labelledby="tab-supervised" class="ai-card">
      <header>
        <h3>Supervised Learning</h3>
        <small class="chip">Labeled data • Predict known targets</small>
      </header>
      {/* Flip card: brief vs. full detail */}
      <div class="ai-flip">
        <div class="front">
          <p>Learn a mapping from inputs to labeled outputs and generalize to unseen data.</p>
          <p>
            <ul class="bullets">
              <li>Supervised learning is the most common paradigm. </li>
              <li>The model learns from data that has been manually labeled with the correct answers.</li>
              <li>It's like a student studying for an exam using a textbook with both questions and an answer key.</li>
              <li>The goal is to learn the relationship between the inputs and the labeled outputs to make accurate predictions on new, unlabeled data.</li>
            </ul>
          </p>
          <em class="hint">Hover or focus to view the real-world example</em>
        </div>
        <div class="back">
          <h4>Real-world example: Credit-card fraud detection</h4>
          <p>A bank trains a model on a massive dataset of past credit card transactions. Each transaction is labeled as either "legitimate" or "fraudulent."
            The model learns the complex patterns associated with fraud (e.g., unusual purchase locations, abnormal spending amounts, rapid transactions).
            When you swipe your card, this trained model analyzes the transaction in real-time and assigns a probability of it being fraudulent, allowing the bank to approve or decline the charge instantly.</p>
        </div>
      </div>
    </article>

    <article id="panel-unsup" role="tabpanel" aria-labelledby="tab-unsup" class="ai-card">
      <header>
        <h3>Unsupervised Learning</h3>
        <small class="chip">No labels • Discover structure</small>
      </header>
      <div class="ai-flip">
        <div class="front">
          <p>Find latent patterns and groups directly from features without predefined answers.</p>
          <ul class="bullets">

              <li>Unsupervised learning involves training a model on data that has no labels or predefined answers.</li>
              <li>The model task is to explore the data and find hidden patterns, structures, or groups on its own.</li>
              <li>It is like being given a box of mixed fruits and asked to sort them into piles based on their
                characteristics, without being told what the fruits are. </li>
          </ul>
          <em class="hint">Hover or focus to view the real-world example</em>
        </div>
        <div class="back">
          <h4>Real-world example: Recommendation engines</h4>
          <p> When you watch a movie on Netflix, the service suggests other content you might like.
            This is often powered by unsupervised learning.
            The algorithm analyzes your viewing history and compares it to the viewing patterns of millions of other users.
            It identifies clusters of users with similar tastes.
            If you and another group of users all liked Movies A, B, and C, and that group also liked Movie D, the system will recommend Movie D to you, assuming you share that hidden taste preference.
            It discovered the "taste group" without any explicit labels.</p>
        </div>
      </div>
    </article>

    <article id="panel-semi" role="tabpanel" aria-labelledby="tab-semi" class="ai-card">
      <header>
        <h3>Semi-Supervised Learning</h3>
        <small class="chip">Few labels • Many unlabeled</small>
      </header>
      <div class="ai-flip">
        <div class="front">
          <p>Leverage a small labeled set plus a large unlabeled pool to improve performance.</p>
          <ul class="bullets">
            <li>This paradigm is a hybrid approach used when you have a small amount of valuable labeled data and a much larger pool of unlabeled data. </li>
            <li>It uses the small labeled set to get started and then leverages the structure of the large unlabeled set to improve its understanding.</li>
          </ul>
          <em class="hint">Hover or focus to view the real-world example</em>
        </div>
        <div class="back">
          <h4>Real-world example: Medical image analysis</h4>
          <p>Obtaining an expert diagnosis for a medical scan (like an MRI or CT scan) is expensive and time-consuming.
            A hospital might have millions of scans (unlabeled data) but only a few thousand that have been carefully diagnosed by a radiologist (labeled data).
            A semi-supervised model first learns from the small, expert-labeled set.
            It then uses this initial knowledge to make sense of the larger unlabeled dataset, significantly improving its diagnostic accuracy beyond what would be possible with the small labeled set alone.</p>
        </div>
      </div>
    </article>

    <article id="panel-rl" role="tabpanel" aria-labelledby="tab-rl" class="ai-card">
      <header>
        <h3>Reinforcement Learning</h3>
        <small class="chip">Act • Observe • Reward</small>
      </header>
      <div class="ai-flip">
        <div class="front">
          <p>Learn a policy by interacting with an environment and optimizing cumulative reward.</p>
          <ul class="bullets">
            <li>Reinforcement learning is about learning through trial and error. A model, or 'agent,' interacts with a dynamic environment and receives feedback in the form of rewards for good actions and penalties for bad ones.</li>
            <li>The agent’s goal is to learn the best strategy, called a 'policy,' to maximize its cumulative reward over time.  </li>
          </ul>
          <em class="hint">Hover or focus to view the real-world example</em>
        </div>
        <div class="back">
          <h4>Real-world example: Robotics and manufacturing</h4>
          <p>In a modern factory, a robotic arm can use reinforcement learning to learn how to pick up objects of various shapes and sizes from a conveyor belt.
            The robot "acts" by moving its arm and gripper. It receives a positive reward when it successfully picks up and places an object in the correct bin.
            It receives a penalty if it drops the object or misses it.
            After millions of attempts (trials), the agent learns the optimal, most efficient sequence of movements to grab any object, adapting its strategy in real-time.</p>
        </div>
      </div>
    </article>
  </div>
</section>

## Supervised Machine Learning

Supervised Machine Learning is a type of AI where you teach a computer to make predictions by showing
it lots of examples with the correct answers. It's like studying for a test with a complete answer key.
The machine "learns" the relationship between the questions (the input data) and the answers (the output labels)
so it can eventually predict answers for new, unseen questions.

The two main types of tasks in supervised learning are **Regression** and **Classification**.

The key difference is the kind of answer the machine learns to predict.

### Regression: Predicting a Number



**Regression** is used when the answer you're trying to predict is a **continuous numerical value**. Think of it as predicting a quantity or an amount on a spectrum. The goal is to figure out the relationship between input variables to predict a number.



#### Example: House Price Prediction



Imagine you want to build a model that predicts the selling price of a house.

- **Input Data (Features):** You would feed the model a large dataset of houses with features like:
- Size in square feet
- Number of bedrooms
- Number of bathrooms
- Age of the house
- Neighborhood
- **Output Data (The "Answer Key"):** For each house in your dataset, you also provide its **actual selling price**. This is the labeled data the model learns from.
- **The Learning Process:** The algorithm analyzes this data to learn how features like size and number of bedrooms affect the final price. For example, it might learn that for every extra 100 sq. ft., the price increases by about $20,000.
- **Prediction:** Once the model is trained, you can give it the features of a *new* house it has never seen before, and it will **predict a specific price**, such as $345,500.

------



### Classification: Predicting a Category 🏷



**Classification** is used when the answer you're trying to predict is a **specific category or class**. Think of it as sorting items into distinct buckets or groups. The output is not a number, but a label.



#### Example: Email Spam Detection



Let's look at a model designed to classify emails as either "Spam" or "Not Spam."

- **Input Data (Features):** The model is given a huge dataset of emails. For each email, it analyzes features like:
- The words used in the subject and body (e.g., "winner," "free," "prize")
- The sender's email address
- Whether the email contains links or attachments
- **Output Data (The "Answer Key"):** Each email in the dataset is pre-labeled by humans as either **"Spam"** or **"Not Spam"**.
- **The Learning Process:** The model learns which features are commonly associated with each category. It learns that emails with words like "congratulations" and suspicious links are very likely to be "Spam," while emails from known contacts are likely "Not Spam."
- **Prediction:** When a *new* email arrives in your inbox, the model analyzes its features and **assigns it to one of the two classes**: "Spam" or "Not Spam," and then routes it to the correct folder.


### Supervised Learning Workflow
It's crucial to understand the workflow and the components that make supervised learning successful. It's not just about feeding data to a machine; it's a structured process of training and evaluation.

Beyond just knowing it uses labeled data, the practical process involves several key steps and concepts.
You can explain more about Supervised Machine Learning by delving into how it works in practice, including the data it needs, the common algorithms used, and the challenges involved in training a model effectively.

#### 1. The Importance of Data: Features and Labels
The success of any supervised model is built on its data. The principle of "garbage in, garbage out" is especially true here.

* **Features** (Inputs): These are the individual measurable properties or characteristics of the phenomenon you're observing. In the house price example, the features are the square footage, number of bedrooms, etc. These are the "questions" you give the model.

* **Labels** (Outputs): This is the correct answer or the final outcome you are trying to predict. For the house, the label is the actual selling price. This is the "answer key" the model learns from.


#### 2. Splitting the Data: Training, Validation, and Testing
You never use all your labeled data to train the model. Doing so would be like giving a student the exact same questions on a final exam that they used to study—you wouldn't know if they actually learned the concepts or just memorized the answers. To avoid this, we split the data into three sets:

<KeyPoints variant="primary" icon="❖">
    <KP term="Training Set (~70%)">
        * This is the largest chunk of data, and it's used to actually teach the model.
        * The algorithm looks for patterns and relationships between the features and labels in this set.
    </KP>
    <KP term="Validation Set (~15%)">
        This data is used to fine-tune the model's parameters and make decisions about its architecture.
        It helps you see how well the model is performing on data it hasn't been trained on, which is crucial for preventing a problem called overfitting.
    </KP>
    <KP term="Testing Set (~15%)">
        This is the final, untouched dataset.
        It's used only once, at the very end, to provide an unbiased evaluation of how the model will likely perform on new, real-world data.
    </KP>
</KeyPoints>

### Common Supervised Learning Algorithms
There are many different algorithms, each with its own strengths. Here are a few popular ones:

| **Algorithm**              | **Description**                                                                                                                                   |
|-----------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|
| **Linear Regression**       | A classic regression algorithm that finds the best-fitting straight line to describe the relationship between features and a numerical outcome.   |
| **Logistic Regression**     | Despite its name, this is a classification algorithm. It's used to predict a categorical outcome (e.g., Yes/No, Spam/Not Spam) by fitting the data to a logistic curve. |
| **Decision Trees**          | A versatile algorithm for both classification and regression. It works by splitting the data into branches based on a series of "if-then-else" questions, resembling a flowchart. |
| **Support Vector Machines** | A powerful classification algorithm that finds the optimal boundary (called a hyperplane) that best separates data points into different classes. |


### Key Challenges: Overfitting and Underfitting
When training a model, the goal is to find a balance between being too simple and too complex.


Analogy: A student who memorizes every word in the textbook but can't answer a slightly different question because they never understood the underlying concepts.

Underfitting: This happens when the model is too simple to capture the underlying structure of the data. It performs poorly on both the training data and new data because it failed to learn the relationships.

Analogy: A student who barely skims the textbook chapter and fails the exam because they didn't learn enough.

<KeyPoints variant="primary" icon="❖">
    <KP term="Overfitting">
        * This happens when the model learns the training data too well, including the noise and random fluctuations.
        * It becomes an expert on the data it has seen but performs poorly on new, unseen data because it hasn't learned the general patterns.

        <div className="example-box">
            <strong>Analogy:</strong>
            <ul className={"no-bullets"}>
                <li>A student who memorizes every word in the textbook but can't answer a slightly different question because they never understood the underlying concepts.</li>
            </ul>
        </div>
    </KP>
    <KP term="Underfitting">
        * This happens when the model is too simple to capture the underlying structure of the data.
        * It performs poorly on both the training data and new data because it failed to learn the relationships.
        <div className="example-box">
            <strong>Analogy:</strong>
            <ul className={"no-bullets"}>
                <li>A student who barely skims the textbook chapter and fails the exam because they didn't learn enough.</li>
            </ul>
        </div>
    </KP>

</KeyPoints>

## Unsupervised Machine Learning: Finding Hidden Patterns

The main goal of **unsupervised learning** is to explore the data and find inherent structure within it.
The two most common tasks are **Clustering** and **Association**.

---

## 1. Clustering

Clustering is the task of grouping similar data points together.
The algorithm automatically organizes the data into **clusters** so that items within the same cluster are more similar to each other than to those in other clusters.

### 🔹 Analogy
Imagine being given a box of assorted **Lego bricks**.
Without any instructions, you'd naturally start sorting them into piles based on **color, shape, or size**.
That's clustering.

### 🔹 Real-World Example
**Customer Segmentation**:
A marketing team can use clustering to group customers based on their **purchasing habits, age, and location**.
This might reveal distinct groups like:
- *Young urban professionals*
- *Suburban families*

This allows the company to create **targeted advertising campaigns** for each group.

---

## 2. Association

Association is a method for discovering interesting **relationships** or **rules** between variables in a large dataset.
It's about finding items that **frequently co-occur**.

### 🔹 Analogy
A supermarket analyst notices that when people buy **bread**, they often buy **butter** too.
This "**if bread, then butter**" relationship is an **association rule**.

### 🔹 Real-World Example
**Market Basket Analysis**:
Used by retailers like **Amazon** and **Netflix**.
When Amazon suggests *“Customers who bought this item also bought...”*, it's using an association algorithm.

Classic story:
A store discovered a link between **diaper** and **beer** sales, then placed them closer together to **boost sales**.

## Comparing the Three Pillars of Machine Learning
<!-- AI Learning Paradigms Table (Scoped) -->
<div class="ai-scope">
    <div class="ai-table-wrap">
        <div class="ai-scroll">
            <table class="ai-table">
                <thead>
                <tr>
                    <th>Aspect</th>
                    <th>Supervised Learning  <span class="badge">Labeled</span></th>
                    <th>Unsupervised Learning <span class="badge">Unlabeled</span></th>
                    <th>Reinforcement Learning  <span class="badge">Rewards</span></th>
                </tr>
                </thead>
                <tbody>
                <tr>
                    <td>Data</td>
                    <td>Learns from <strong>labeled data</strong> (data with a known, correct answer).</td>
                    <td>Learns from <strong>unlabeled data</strong> (no correct answers provided).</td>
                    <td>Does not use a fixed dataset; <strong>generates data by interacting</strong> with an environment.</td>
                </tr>
                <tr>
                    <td>Goal</td>
                    <td>To <strong>predict an outcome</strong> by mapping inputs to a known label.</td>
                    <td>To <strong>discover hidden patterns</strong> or underlying structure.</td>
                    <td>To <strong>learn a policy</strong>—a sequence of actions that maximizes cumulative reward.</td>
                </tr>
                <tr>
                    <td>How it Learns</td>
                    <td>A “supervisor/teacher” provides an <strong>answer key (labels)</strong> to learn from.</td>
                    <td><strong>Explores</strong> the data on its own to find meaningful connections and groupings.</td>
                    <td><strong>Trial and error</strong>: receives rewards for good actions and penalties for bad ones.</td>
                </tr>
                <tr>
                    <td>Core Question</td>
                    <td><em>Given past labeled data, can we predict the value or category of new data?</em></td>
                    <td><em>What hidden patterns or groups exist within this data?</em></td>
                    <td><em>Which sequence of actions yields the most reward?</em></td>
                </tr>
                <tr>
                    <td>Examples</td>
                    <td>House‑price prediction; Email spam vs. not‑spam.</td>
                    <td>Customer segmentation; Market‑basket co‑occurrence.</td>
                    <td>Game‑playing (chess); Robot locomotion; Data‑center cooling optimization.</td>
                </tr>
                </tbody>
            </table>
        </div>
    </div>
</div>

# The Machine Learning Project Lifecycle

Think of this as a roadmap that data scientists follow to take an idea and turn it into a functional AI application.

---

## 1. Define the Problem
First, you must clearly state the **goal**.
- What question are you trying to answer?
- What do you want to predict?

This determines the **type of problem** (e.g., regression, classification, clustering) and the kind of data you'll need.

**Example:**
*"We want to predict which customers are likely to stop using our service next month"* (a classification problem).

---

## 2. Data Collection and Preparation
This is often the most **time-consuming** part. You need to gather relevant data and then clean it up.

- **Collection:** Get data from databases, files, APIs, etc.
- **Preparation (Cleaning):** Handle missing values, remove duplicate entries, correct errors, and format the data.

⚠️ **Remember:** Garbage in, garbage out.

---

## 3. Exploratory Data Analysis (EDA)
Before building a model, you need to **understand your data**.

- Use **statistics** and **visualizations** (charts, graphs)
- Find **patterns**, **spot anomalies**, and **identify relationships** between features

---

## 4. Model Selection and Training
Choose one or more **machine learning algorithms** appropriate for your problem (e.g., Linear Regression, Decision Tree).
- Train the model by feeding it your prepared training data.
- This is where the model **“learns” patterns**.

---

## 5. Model Evaluation
After training, check how well your model performs.

- Use unseen **test data** to evaluate it.
- Measure performance with **metrics**:
- Accuracy (for classification)
- Mean Squared Error (for regression)

This tells you if the model is actually good at making predictions.

---

## 6. Parameter Tuning and Deployment

- **Tuning:** Adjust **hyperparameters** to improve performance.
- **Deployment:** Integrate the model into a real-world application (mobile app, website, business tool) so it can start making **live predictions**.
---

# The Machine Learning Toolkit 🛠️

While the concepts are universal, the actual implementation happens using a specific set of powerful technologies, primarily centered around the **Python programming language**.

---

## 1. The Core Language: Python
Python is the **undisputed king** of machine learning.
- Its **simple, readable syntax** makes it easy to learn.
- It has a **massive ecosystem** of open-source libraries for data science and AI.
- While other languages like **R** are also used (especially in statistics), **Python is the industry standard**.

---

## 2. The Essential Libraries
These are the **workhorses** for nearly every step of the machine learning lifecycle:

- **NumPy**
Short for *Numerical Python*.
Provides tools for working with large, multi-dimensional **arrays and matrices**, the core data structures for scientific computing.

- **Pandas**
The go-to tool for **data preparation and analysis** (Lifecycle Steps 2 & 3).
Works with **DataFrames**, allowing you to load, clean, manipulate, filter, and combine data easily.

- **Matplotlib & Seaborn**
Essential for **data visualization** (Exploratory Data Analysis, Step 4).
Help create charts and graphs to spot **patterns** and **relationships**.

- **Scikit-learn**
The most important library for **traditional machine learning**.
Provides tools for:
- Algorithms (Linear Regression, Decision Trees, SVM, Clustering, etc.)
- Model evaluation and tuning

---

## 3. Deep Learning Frameworks 🧠
For more complex tasks (e.g., computer vision, NLP), specialized frameworks are used:

- **TensorFlow**
Developed by Google.
A powerful, **scalable framework** for building large-scale neural networks.

- **PyTorch**
Developed by Meta (Facebook).
Known for its **flexibility** and widely adopted in the **research community**.

---
# Machine Learning Toolkit: Quick Comparison 🛠️

| **Category**              | **Tool/Library**       | **Purpose / Role**                                                                                 | **Notes** |
|----------------------------|------------------------|-----------------------------------------------------------------------------------------------------|-----------|
| **Core Language**          | **Python**         | Simple, readable syntax with a massive ecosystem for ML and AI                                      | Industry standard; R used in statistics |
| **Essential Libraries**    | **NumPy**              | Scientific computing with multi-dimensional arrays and matrices                                     | Foundation for most other libraries |
|                            | **Pandas**             | Data preparation & analysis using DataFrames                                                        | Steps 2 & 3 of ML Lifecycle |
|                            | **Matplotlib & Seaborn** | Data visualization (charts, graphs, spotting patterns)                                               | Step 4: Exploratory Data Analysis |
|                            | **Scikit-learn**       | Traditional ML algorithms (Regression, Decision Trees, SVM, Clustering) + evaluation & tuning tools | Steps 5, 6, 7 |
| **Deep Learning Frameworks** | **TensorFlow**        | Scalable framework for building large-scale neural networks                                         | Developed by Google |
|                            | **PyTorch**            | Flexible framework widely used in research, supports dynamic computation graphs                     | Developed by Meta (Facebook) |

## From Theory to Practice: Lab Overview 🧪

You’ve built a strong theoretical foundation. Now it’s time to **apply** it and see how machine learning solves real problems.
In the upcoming labs, you’ll get hands‑on with the three most fundamental ML tasks.

---

### 🚗 Lab 1 — Supervised Learning: Regression
You’ll build a model to **predict a number**. Using a vehicles dataset, you’ll predict a car’s **fuel efficiency (MPG)** from its features.

**You’ll practice:** EDA → feature selection → train/test split → Linear Regression / Random Forest Regressor → RMSE/MAE/R² → basic model tuning.

---

### 🌸 Lab 2 — Supervised Learning: Classification
You’ll train a model to **predict a category**. With the classic **Iris** dataset, you’ll classify a flower’s **species** from its measurements.

**You’ll practice:** data scaling → Logistic Regression / k‑NN / Decision Tree → confusion matrix → accuracy/precision/recall/F1 → cross‑validation.

---

### 🧩 Lab 3 — Unsupervised Learning: Clustering
You’ll ask a model to **discover hidden groups**. With an unlabeled **customers** dataset, you’ll segment users into **behavior‑based clusters**.

**You’ll practice:** feature standardization → k‑means → elbow & silhouette methods → cluster profiling → insights for marketing actions.

---
